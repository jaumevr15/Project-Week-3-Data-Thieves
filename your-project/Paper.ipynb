{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Brief Exploration of Porn Statistics\n",
    "Mar√≠a Platas, Alieldin Ramadan, Jaume Vicens\n",
    "November 2019 - Ironhack Barcelona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Porn is one of the most controversial elements in today's Internet. Known by most but openly admitted by a very few. Porn websites are source of huge, enormous databases of content, categories, users and algorithms that can be compared to the ones from most accessible sites like Youtube or Facebook. \n",
    "\n",
    "This umbrageous, but at the same time vast and interesting topic seemed perfect to be analyzed to have a better understanding of an unknown but still very big part the current consumption of internet.\n",
    "\n",
    "We are currently halfway the completion of the Data Analytics Bootcamp, a 9-weeks full-time course where Python, SQL, Pandas and Tableau are covered, and these tools together make a difference when trying to analyze the available data.\n",
    "\n",
    "In order to understand a bit better porn statistics, type of content and currents, we had a few questions we wanted to answer:\n",
    "1. Which are the main categories, or tags used at porn sites?\n",
    "2. Which are the most popular categories, and which ones have more content?\n",
    "3. Which are the best rated categories?\n",
    "4. Is there a correlation between the number of videos that a category has and the average views per video?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "For this project, we used three different sources to get the most diverse and complete information possible:\n",
    "1. **Redtube Api** [api.redtube.com] The official Redtube Api, which allowed a maximum of 30000 requests per day. 51901 rows of data.\n",
    "2. **Pornhub Database, csv file** from Kaggle [www.kaggle.com], with 191532 rows of data.\n",
    "3. **Xhamster Database, csv file** from Sexualitics [https://sexualitics.github.io/] with 785119 rows of data which we limited to 100000 for easy manipulation.\n",
    "\n",
    "The information decided to use and manage is the following:\n",
    "[Video title]: Name of the video.\n",
    "[Number of views]: Accumulated amount of views per video.\n",
    "[Rating]: Average rating per video, from 0.0 to 1000\n",
    "[Category 1]: Category or tag of the video.\n",
    "[Category 2]: Second category of the video.\n",
    "[Category 3]: Third category of the video.\n",
    "[Website]: Source of the video *Either Redtube, Pornhub, Xhamster. \n",
    "*A video has always a designated category [Category_1] but can also have others [Category_2] and [Category_3] which are optional. The original dataset varies from 1 to 20 categories in one video. We decided to limit it to three to standarize it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "Each database was accessed, wrangled and cleaned separately to create an uniform database aligned with the relevant needed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed libraries, adapting path and ignoring scientific notation\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sqlalchemy\n",
    "#import os\n",
    "os.chdir('databases')\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Redtube_list.txt', 'r') as filehandle:\n",
    "    df = json.load(filehandle)\n",
    "    \n",
    "video = []\n",
    "for i in df:\n",
    "    for key, value in i.items():\n",
    "        if key == 'video':\n",
    "            video.append(value)\n",
    "\n",
    "views = np.array([])\n",
    "rating = np.array([])\n",
    "titles = np.array([])\n",
    "\n",
    "for dict1 in video:\n",
    "    for key1, value1 in dict1.items():\n",
    "        if key1 == 'views':\n",
    "            views = np.append(views, np.array([value1]))\n",
    "        elif key1 == 'rating':\n",
    "            rating = np.append(rating, np.array([value1]))\n",
    "        elif key1 == 'title':\n",
    "            titles = np.append(titles, np.array([value1]))\n",
    "\n",
    "categories = pd.DataFrame(tags)\n",
    "\n",
    "arrays = {'Title': titles, 'Number_of_Views': views, 'Rating': rating}\n",
    "table = pd.DataFrame(data=arrays\n",
    "                     \n",
    "rt_table = pd.merge(table, categories, left_index=True, right_index=True)\n",
    "                     \n",
    "rt_table['Website'] = 'Redtube'\n",
    "                     \n",
    "rt_table = full_table.astype({'Title': str, 'Number_of_Views': int, 'Rating': float, 'Category_1': str, 'Category_2': str, 'Category_3': str, 'Website': str})\n",
    "                     \n",
    "rt_table.info()\n",
    "\n",
    "rt_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pornhub CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access to database and first sight.\n",
    "ph = pd.read_csv('/Users/Maria/Desktop/tumbzilla_labels.csv', index_col = 0)\n",
    "ph.columns\n",
    "\n",
    "#Taking out unneeded columns\n",
    "ph.drop(['img_source', 'video_link','tags', 'length', 'quality' ], axis = 1, inplace=True)\n",
    "\n",
    "def cast_to_list(categories):\n",
    "    if pd.isnull(categories):\n",
    "        return categories\n",
    "    return [item.strip() for item in categories.split(\"__\")]\n",
    "\n",
    "ph['categories']= ph['categories'].apply(cast_to_list)\n",
    "\n",
    "categories = ph['categories'].apply(pd.Series\n",
    "categories.drop(columns = [3,4,5,6,7,8,9,10,11], inplace = True)\n",
    "categories.rename(columns = {0:'Category_1', 1:'Category_2', 2:'Category_3'}, inplace = True)\n",
    "                                                                     \n",
    "ph_merged = ph.merge(right = categories, left_index = True, right_index=True)\n",
    "ph_merged['Website'] = \"Pornhub\"\n",
    "ph_merged.rename(columns = {'nb_views':'Number_of_Views','title':'Title','voting':'Rating'}, inplace = True)     \n",
    "ph_merged = ph_merged[['Title', 'Number_of_Views', 'Rating', 'Category_1', 'Category_2', 'Category_3', 'Website']]   \n",
    "                                    \n",
    "ph_merged.head()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xHamster CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xhamster dataset comes from https://sexualitics.github.io/ which contains 786120 rows containing videos' data.\n",
    "#We select the columns we are interested in.\n",
    "df = pd.read_csv('../../xhamster.csv')\n",
    "df_clean = df[['id','title','channels','nb_views']]\n",
    "df_clean = df_clean[df_clean['channels'].notnull()]\n",
    "df_clean = df_clean['channels'].apply(pd.Series)\n",
    "\n",
    "#The category column contains all the categories together, divided by a coma.\n",
    "#In order to split the strings inside the column 'category' we do it separately:\n",
    "three_cat = df_new2[0].str.split(pat=',', n=4, expand=True)\n",
    "cat1 = pd.DataFrame(three_cat[0].str.strip(to_strip=\"[,'] \\n\")) \n",
    "cat2 = pd.DataFrame(three_cat[1].str.strip(to_strip=\"[,'] \\n\")) \n",
    "cat3 = pd.DataFrame(three_cat[2].str.strip(to_strip=\"[,'] \\n\"))\n",
    "\n",
    "#We create the ultimate cleaned database by taking the original df table\n",
    "xh_table = df[['title','nb_views','channels']]\n",
    "xh_table = xh_table[df_real['channels'].notnull()]\n",
    "\n",
    "#We append the cleaned Category columns to the ultimate chart\n",
    "xh_table['Category_1'] = cat1\n",
    "xh_table['Category_2'] = cat2\n",
    "xh_table['Category_3'] = cat3\n",
    "xh_table.drop('channels',axis=1,inplace=True)\n",
    "xh_table['Website'] = 'Xhamster'\n",
    "\n",
    "#As agreed with the team, we rename the columns by convention\n",
    "xh_table = xh_table.rename(columns={'title': 'Title', 'nb_views': 'Number_of_Views'})\n",
    "\n",
    "#As the original cleaned dataset is 700000 rows, we limit it to 100000 most viewed ones\n",
    "xh_100 = xh_table.sort_values('Number_of_Views',ascending=False)\n",
    "xh_100 = xh_100.head(100000)\n",
    "xh_100 = xh_100.drop('channels',axis=1)\n",
    "xh_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Category Table Dilemma\n",
    "With above actions, we made it to merge three different sources into one single dataset with a total of 343433 rows, with the information we needed to analyze. But when the analysis through Tableau started, we noticed some biased information as we ignored [Category_2] and [Category_3] elements. \n",
    "For this reason, we decided to create another dataset where we combined the elements in the categories in the three columns, so we could get a better overview of their elements.\n",
    "\n",
    "At the same time, some categories had similar names which we could consider as duplicates -for example: 'Anal sex' and 'Anal' could count as the same one, or 'Lesbian' and 'Lesbians'-. An extra layer of cleaning was needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Count_Total</th>\n",
       "      <th>Total_views</th>\n",
       "      <th>Avg_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2807189.0</td>\n",
       "      <td>71.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60fps</td>\n",
       "      <td>315.0</td>\n",
       "      <td>36959579.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>501.0</td>\n",
       "      <td>81311080.0</td>\n",
       "      <td>80.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amateur</td>\n",
       "      <td>72524.0</td>\n",
       "      <td>15083247430.0</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anal</td>\n",
       "      <td>27357.0</td>\n",
       "      <td>4808210528.0</td>\n",
       "      <td>79.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  Count_Total   Total_views  Avg_ratings\n",
       "0       3D         40.0     2807189.0         71.7\n",
       "1    60fps        315.0    36959579.0         73.0\n",
       "2       69        501.0    81311080.0         80.2\n",
       "3  Amateur      72524.0 15083247430.0         74.9\n",
       "4     Anal      27357.0  4808210528.0         79.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We proceed to play with The Video Dataset to get the right Category Dataset.\n",
    "df = pd.read_csv(\"1_videos_combined_dataset.csv\", encoding='utf8', sep=\";\", index_col = 0,low_memory=False)\n",
    "\n",
    "#We start by grouping by 'Category_1'\n",
    "df_g = pd.DataFrame(df.groupby('Category_1', as_index = False).count())\n",
    "df_g.drop(columns = ['Number_of_Views', 'Rating', 'Category_2', 'Category_3','Website', 'Unnamed: 8'], inplace = True)\n",
    "\n",
    "#We get each category and the total count of elements that have them as 'Category 1'\n",
    "df_g.columns = ['Category', 'Count1']\n",
    "df_g['Count1'].sum()\n",
    "\n",
    "#Repeat the process for 'Category 2' and 'Category 3'\n",
    "df_g2 = pd.DataFrame(df.groupby('Category_2', as_index = False).count())\n",
    "df_g2.drop(columns = ['Number_of_Views', 'Rating', 'Category_1', 'Category_3','Website', 'Unnamed: 8'], inplace = True)\n",
    "df_g2.columns = ['Category', 'Count2']\n",
    "\n",
    "df_g3 = pd.DataFrame(df.groupby('Category_3', as_index = False).count())\n",
    "df_g3.drop(columns = ['Number_of_Views', 'Rating', 'Category_1', 'Category_2','Website', 'Unnamed: 8'], inplace = True)\n",
    "df_g3.columns = ['Category', 'Count3']\n",
    "\n",
    "#We proceed to merge\n",
    "df_final_count0 = df_g.merge(df_g2, on='Category', how ='outer')\n",
    "df_final = df_final_count0.merge(df_g3, on = 'Category', how ='outer')\n",
    "\n",
    "#Replacing NaN for 0 and summing the counts\n",
    "df_final.fillna(0, inplace = True)\n",
    "df_final['Count_Total'] = df_final['Count1'] +  df_final['Count2'] +  df_final['Count3']\n",
    "\n",
    "#Now we want to aggregate the number of views to get the total combined value and merge to the original one.\n",
    "df_V = pd.DataFrame(df.groupby('Category_1', as_index = False).agg({'Number_of_Views':'sum','Rating':'mean'}))\n",
    "df_V.columns = ['Category', 'Total_views', 'Avg_ratings']\n",
    "df_final = df_final.merge(df_V, on = 'Category', how ='outer')\n",
    "df_final.drop(columns = ['Count1', 'Count2', 'Count3'], inplace = True)\n",
    "\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Master Datasets\n",
    "### The Video Dataset\n",
    "343433 rows from three different sources. Structured as following:\n",
    "[Video title]: Name of the video. (String)\n",
    "[Number of views]: Accumulated amount of views per video. (Float)\n",
    "[Rating]: Average rating per video, from 0.0 to 1000. (Float)\n",
    "[Category 1]: Category or tag of the video. (String)\n",
    "[Category 2]: Second category of the video. (String)\n",
    "[Category 3]: Third category of the video. (String)\n",
    "[Website]: Source of the video *Either Redtube, Pornhub, Xhamster. (String)\n",
    "\n",
    "\n",
    "### The Category Dataset\n",
    "187 rows of unique categories extracted from [The Video Dataset]. Structured as following:\n",
    "[Category]: Name of the category. (String)\n",
    "[Count_Total]: Total number of elements -videos- in the category. (Float)\n",
    "[Total_views_all]: Total number of views from each of the videos in the category. (Float)\t[Avg_ratings_all]: Total ratings from each of the videos in the category. (Float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Analysis\n",
    "After cleaning the original three databases and creating the two Videos & Categories Datasets. We are able to proceed with the analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
